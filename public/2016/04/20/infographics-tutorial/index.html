<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.32.2" />


<title>Creating an Infographic with infogram - Paul Oldhams Analytics Blog</title>
<meta property="og:title" content="Creating an Infographic with infogram - Paul Oldhams Analytics Blog">



  








<link href='//cdn.bootcss.com/highlight.js/9.11.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/paul-oval.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="https://github.com/poldham">GitHub</a></li>
    
    <li><a href="https://twitter.com/junglepaul">Twitter</a></li>
    
    <li><a href="https://github.com/wipo-analytics">WIPO Analytics</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">42 min read</span>
    

    <h1 class="article-title">Creating an Infographic with infogram</h1>

    
    <span class="article-date">2016/04/20</span>
    

    <div class="article-content">
      <p>In this article we will use RStudio to prepare patent data for visualisation in an infographic using the online software tool <a href="https://infogram.com/?rc=paid0sem0branded0search0&amp;gclid=EAIaIQobChMIw6KgvMiq2AIViLvtCh2fpgxhEAAYASAAEgKR2PD_BwE">infogram</a>.</p>
<p>Infographics are a popular way of presenting data in a way that is easy for a reader to understand without reading a long report. Infographics are well suited to presenting summaries of data with simple messages about key findings. A good infographic can encourage the audience to read a detailed report and is a tool for engagement with audiences during presentations of the findings of patent research.</p>
<p>Some patent offices have already been creating infographics as part of their reports to policy makers and other clients. The Instituto Nacional de Propiedade Industrial (INPI) in Brazil produces regular two page <a href="http://www.inpi.gov.br/menu-servicos/informacao/radares-tecnologicos">Technology Radar</a> (Radar Tecnologico) consisting of charts and maps that briefly summarise more detailed research on subjects such as <a href="http://www.inpi.gov.br/menu-servicos/arquivos-cedin/n08_radar_tecnologico_nano_residuos_versao_resumida_ingles_atualizada_20160122.pdf">Nanotechnology in Waste Management</a>. <a href="http://www.wipo.int/patentscope/en/programs/patent_landscapes/">WIPO Patent Landscape Reports</a>, which go into depth on patent activity for a particular area, are accompanied by one page infographics that have proved very popular such as the infographic accompanying a recent report on <a href="http://www.wipo.int/export/sites/www/patentscope/en/programs/patent_landscapes/reports/documents/assistivedevices_infographic.pdf">assistive devices</a>.</p>
<p>A growing number of companies are offering online infographic software services such as <a href="https://infogr.am/app/#/library">infogr.am</a>,<a href="http://www.easel.ly">easel.ly</a> <a href="https://magic.piktochart.com/templates">piktochart.com</a>, <a href="https://www.canva.com/create/infographics/">canva.com</a> or <a href="https://venngage.com">venngage.com</a> to mention only a selection of the offerings out there. The <a href="http://www.coolinfographics.com/tools/">Cool Infographics website</a> provides a useful overview of available tools.</p>
<p>One feature of many of these services is that they are based on a freemium model. Creating graphics is free but the ability to export files and the available formats for export of your masterpiece (e.g. high resolution or .pdf) often depend on upgrading to a monthly account at varying prices. In this chapter we test drive <a href="https://infogr.am/app/#/library">infogr.am</a> as a chart friendly service, albeit with export options that depend on a paid account.</p>
<p>This article is divided into two sections.</p>
<ol style="list-style-type: decimal">
<li>In part 1 we focus on using RStudio to prepare patent data for visualisation in infographics software using the <code>dplyr</code>, <code>tidyr</code> and <code>stringr</code> packages. This involves dealing with common problems with patent data such as concatenated fields, white space and creating counts of data fields. Part 1 is intended for those starting out using R and assumes no prior knowledge of R.</li>
<li>In part 2 we produce an infographic from the data using <a href="https://infogr.am/app/#/library">infogr.am</a>.</li>
</ol>
<p>This article is now a chapter in the <a href="https://wipo-analytics.github.io/">WIPO Manual on Open Source Patent Analytics</a>. You can read the chapter in electronic book format <a href="https://wipo-analytics.github.io/patent-infographics-with-r.html">here</a> and find all the materials including presentations at the <a href="https://github.com/wipo-analytics">WIPO Analytics Github homepage</a>.</p>
<div id="getting-started" class="section level2">
<h2>Getting Started</h2>
<p>To start with we need to ensure that RStudio and R for your operating system are installed by following the instructions on the RStudio website <a href="https://www.rstudio.com/products/rstudio/download/">here</a>. Do not forget to follow the link to also <a href="https://cran.rstudio.com">install R for your operating system</a>.</p>
<p>When working in RStudio it is good practice to work with projects. This will keep all of the files for a project in the same folder. To create a project go to File, New Project and create a project. Call the project something like infographic. Any file you create and save for the project will now be listed under the Files tab in RStudio.</p>
<p>R works using packages (libraries) and there are around 7,490 of them for a whole range of purposes. We will use just a few of them. To install a package we use the following. Copy and paste the code into the Console and press enter.</p>
<pre class="r"><code>install.packages(&quot;tidyverse&quot;)  # the group of packages you will need</code></pre>
<p>Packages can also be installed by selecting the Packages tab and typing the name of the package.</p>
<p>To load the packages (libraries) use the following or check the tick box in the Packages pane.</p>
<pre class="r"><code>library(readr)
library(dplyr)
library(tidyr)
library(stringr)
library(ggplot2)</code></pre>
<p>We are now ready to go.</p>
</div>
<div id="load-a-.csv-file-using-readr" class="section level2">
<h2>Load a .csv file using <code>readr</code></h2>
<p>We will work with the <code>pizza_medium_clean</code> dataset in the online <a href="https://github.com/wipo-analytics/opensource-patent-analytics/tree/master/2_datasets">Github Manual repository</a>. If manually downloading a file remember to click on the file name and select <code>Raw</code> to download the actual file.</p>
<p>We can use the easy to use <code>read_csv()</code> function from the <code>readr</code> package to quickly read in our pizza data directly from the Github repository. Note the <code>raw</code> at the beginning of the filename.</p>
<pre class="r"><code>library(readr)
pizza &lt;- read_csv(&quot;https://github.com/wipo-analytics/opensource-patent-analytics/blob/master/2_datasets/pizza_medium_clean/pizza.csv?raw=true&quot;)</code></pre>
<p><code>readr</code> will display a warning for the file arising from its efforts to parse publication dates on import. We will ignore this as we will not be using this field.</p>
<p>As an alternative to importing directly from Github download the file and in RStudio use <code>File &gt; Import Dataset &gt; From .csv</code>. If you experience problems with direct import of a file the File &gt; Import Dataset approach will give you a range of easy to use controls for figuring this out (e.g. where .csv is actually a tab separated file).</p>
</div>
<div id="viewing-data" class="section level2">
<h2>Viewing Data</h2>
<p>We can view data in a variety of ways.</p>
<ol style="list-style-type: decimal">
<li>In the console:</li>
</ol>
<pre class="r"><code>pizza</code></pre>
<pre><code>## # A tibble: 9,996 x 31
##                                                               applicants_cleaned
##                                                                            &lt;chr&gt;
##  1                                                                          &lt;NA&gt;
##  2 Ventimeglia Jamie Joseph; Ventimeglia Joel Michael; Ventimeglia Thomas Joseph
##  3                                              Cordova Robert; Martinez Eduardo
##  4                                                       Lazarillo De Tormes S L
##  5                                                                          &lt;NA&gt;
##  6                                                            Depoortere, Thomas
##  7                                                              Frisco Findus Ag
##  8                                                    Bicycle Tools Incorporated
##  9                                                            Castiglioni, Carlo
## 10                                                                          &lt;NA&gt;
## # ... with 9,986 more rows, and 30 more variables:
## #   applicants_cleaned_type &lt;chr&gt;, applicants_organisations &lt;chr&gt;,
## #   applicants_original &lt;chr&gt;, inventors_cleaned &lt;chr&gt;,
## #   inventors_original &lt;chr&gt;, ipc_class &lt;chr&gt;, ipc_codes &lt;chr&gt;,
## #   ipc_names &lt;chr&gt;, ipc_original &lt;chr&gt;, ipc_subclass_codes &lt;chr&gt;,
## #   ipc_subclass_detail &lt;chr&gt;, ipc_subclass_names &lt;chr&gt;,
## #   priority_country_code &lt;chr&gt;, priority_country_code_names &lt;chr&gt;,
## #   priority_data_original &lt;chr&gt;, priority_date &lt;chr&gt;,
## #   publication_country_code &lt;chr&gt;, publication_country_name &lt;chr&gt;,
## #   publication_date &lt;chr&gt;, publication_date_original &lt;chr&gt;,
## #   publication_day &lt;int&gt;, publication_month &lt;int&gt;, publication_number &lt;chr&gt;,
## #   publication_number_espacenet_links &lt;chr&gt;, publication_year &lt;int&gt;,
## #   title_cleaned &lt;chr&gt;, title_nlp_cleaned &lt;chr&gt;,
## #   title_nlp_multiword_phrases &lt;chr&gt;, title_nlp_raw &lt;chr&gt;,
## #   title_original &lt;chr&gt;</code></pre>
<ol start="2" style="list-style-type: decimal">
<li><p>In Environment click on the blue arrow to see in the environment. Keep clicking to open a new window with the data.</p></li>
<li><p>Use the <code>View()</code> command (for data.frames and tables)</p></li>
</ol>
<pre class="r"><code>View(pizza)</code></pre>
<p>If possible use the View() command or environment. The difficulty with the console is that large amounts of data will simply stream past.</p>
</div>
<div id="identifying-types-of-object" class="section level2">
<h2>Identifying Types of Object</h2>
<p>We often want to know what type of object we are working with and more details about the object so we know what to do later. Here are some of the most common commands for obtaining information about objects.</p>
<pre class="r"><code>class(pizza)  ## type of object
names(pizza)  ## names of variables
str(pizza)  ## structure of object
dim(pizza)  ## dimensions of the object</code></pre>
<p>The most useful command in this list is <code>str()</code> because this allows us to access the structure of the object and see its type.</p>
<pre class="r"><code>str(pizza, max.level = 1)</code></pre>
<p><code>str()</code> is particularly useful because we can see the names of the fields (vectors) and their type. Most patent data is a character vector with dates forming integers.</p>
</div>
<div id="working-with-data" class="section level2">
<h2>Working with Data</h2>
<p>We will often want to select aspects of our data to focus on a specific set of columns or to create a graph. We might also want to add information, notably numeric counts.</p>
<p>The <code>dplyr</code> package provides a set of very handy functions for selecting, adding and counting data. The <code>tidyr</code> and <code>stringr</code> packages are sister packages that contain a range of other useful functions for working with our data. We have covered some of these in other chapters on graphing using R but will go through them quickly and then pull them together into a function that we can use across our dataset.</p>
<div id="select" class="section level3">
<h3>Select</h3>
<p>In this case we will start by using the <code>select()</code> function to limit the data to specific columns. We can do this using their names or their numeric position (best for large number of columns e.g. 1:31). In <code>dplyr</code>, unlike most R packages, existing character columns do not require <code>&quot;&quot;</code>.</p>
<pre class="r"><code>library(dplyr)
pizza_number &lt;- select(pizza, publication_number, publication_year)</code></pre>
<p>We now have a new data.frame that contains two columns. One with the year and one with the publication number. Note that we have created a new object called pizza_number using <code>&lt;-</code> and that after <code>select()</code> we have named our original data and the columns we want. A fundamental feature of select is that it will drop columns that we do not name. So it is best to create a new object using <code>&lt;-</code> if you want to keep your original data for later work.</p>
</div>
<div id="adding-data-with-mutate" class="section level3">
<h3>Adding data with <code>mutate()</code></h3>
<p><code>mutate()</code> is a <code>dplyr</code> function that allows us to add data based on existing data in our data frame, for example to perform a calculation. In the case of patent data we normally lack a numeric field to use for counts. We can however assign a value to our publication field by using sum() and the number 1 as follows.</p>
<pre class="r"><code>library(dplyr)
pizza_number &lt;- mutate(pizza_number, n = sum(publication_number = 1))</code></pre>
<p>When we view <code>pizza_number</code> we now have a value of 1 in the column <code>n</code> for each publication number.</p>
<p>Note that in patent data a priority, application, publication or family number may occur multiple times and we would want to reduce the dataset to distinct records. For that we would use <code>n_distinct(pizza_number$publication_number)</code> from <code>dplyr</code> or <code>unique(pizza_number$publication_number)</code> from base R. Because the publication numbers are unique we can proceed.</p>
</div>
<div id="counting-data-using-count" class="section level3">
<h3>Counting data using <code>count()</code></h3>
<p>At the moment, we have multiple instances of the same year (where a patent publication occurs in that year). We now want to calculate how many of our documents were published in each year. To do that we will use the <code>dplyr</code> function <code>count()</code>. We will use the publication_year and add <code>wt =</code> (for weight) with <code>n</code> as the value to count.</p>
<pre class="r"><code>library(dplyr)
pizza_total &lt;- count(pizza_number, publication_year, wt = n)
pizza_total</code></pre>
<pre><code>## # A tibble: 58 x 2
##    publication_year    nn
##               &lt;int&gt; &lt;dbl&gt;
##  1             1940     1
##  2             1954     1
##  3             1956     1
##  4             1957     1
##  5             1959     1
##  6             1962     1
##  7             1964     2
##  8             1966     1
##  9             1967     1
## 10             1968     8
## # ... with 48 more rows</code></pre>
<p>When we now examine pizza_total, we will see the publication year and a summed value for the records in that year.</p>
<p>This raises the question of how we know that R has calculated the count correctly. We already know that there are 9996 records in the pizza dataset. To check our count is correct we can simply use sum and select the column we want to sum using <code>$</code>.</p>
<pre class="r"><code>library(dplyr)
sum(pizza_total$nn)</code></pre>
<pre><code>## [1] 9996</code></pre>
<p>So, all is good and we can move on. The <code>$</code> sign is one of the main ways of subsetting to tell R that we want to work with a specific column (the others are “[” and “[[”).</p>
</div>
<div id="rename-a-field-with-rename" class="section level3">
<h3>Rename a field with <code>rename()</code></h3>
<p>Next we will use <code>rename()</code> from <code>dplyr</code> to rename the fields. Note that understanding which field require quote marks can take some effort. In this case renaming the character vector publication_year as “pubyear” requires quotes while renaming the numeric vector “n” does not.</p>
<pre class="r"><code>library(dplyr)
pizza_total &lt;- rename(pizza_total, pubyear = publication_year, publications = nn) %&gt;% 
    print()</code></pre>
<pre><code>## # A tibble: 58 x 2
##    pubyear publications
##      &lt;int&gt;        &lt;dbl&gt;
##  1    1940            1
##  2    1954            1
##  3    1956            1
##  4    1957            1
##  5    1959            1
##  6    1962            1
##  7    1964            2
##  8    1966            1
##  9    1967            1
## 10    1968            8
## # ... with 48 more rows</code></pre>
</div>
<div id="make-a-quickplot-with-qplot" class="section level3">
<h3>Make a quickplot with <code>qplot()</code></h3>
<p>Using the <code>qplot()</code> function in <code>ggplot2</code> we can now draw a quick line graph. Note that qplot() is unusual in R because the data (pizza_total) appears after the coordinates. We will specify that we want a line using <code>geom =</code> (if geom is left out it will be a scatter plot). This will give us an idea of what our plot might look like in our infographic and actions we might want to take on the data.</p>
<pre class="r"><code>library(ggplot2)
qplot(x = pubyear, y = publications, data = pizza_total, geom = &quot;line&quot;)</code></pre>
<p><img src="/post/2016-04-20-infographics_files/figure-html/qplot-1.png" width="800px" style="display: block; margin: auto;" /></p>
<!---![](images_foot/infogram/fig1_infographic.png)--->
<p>The plot reveals a data cliff in recent years. This normally reflects a lack of data for the last 2-3 years as recent documents feed through the system en route to publication.</p>
<p>It is a good idea to remove the data cliff by cutting the data 2-3 years prior to the present. In some cases two years is sufficient, but 3 years is a good rule of thumb.</p>
<p>We also have long tail of data with limited data from 1940 until the late 1970s. Depending on our purposes with the analysis we might want to keep this data (for historical analysis) or to focus in on a more recent period.</p>
<p>We will limit our data to specific values using the <code>dplyr</code> function <code>filter()</code>.</p>
</div>
<div id="filter-data-using-filter" class="section level3">
<h3>Filter data using <code>filter()</code></h3>
<p>In contrast with <code>select()</code> which works with columns, <code>filter()</code> in <code>dplyr</code> works with rows. In this case we need to filter on the values in the pubyear column. To remove the data prior to 1990 we will use the greater than or equal to operator <code>&gt;=</code> on the pubyear column and we will use the less than or equal to <code>&lt;=</code> operator on the values after 2012.</p>
<p>One strength of <code>filter()</code> in <code>dplyr</code> is that it is easy to filter on multiple values in the same expression (unlike the very similar filter function in base R). The use of <code>filter()</code> will also remove the 30 records where the year is recorded as NA (Not Available). We will write this file to disk using the simple <code>write_csv()</code> from <code>readr</code>. To use <code>write_csv()</code> we first name our data (<code>pizza_total</code>) and then provide a file name with a .csv extension. In this case and other examples below we have used a descriptive file name bearing in mind that Windows systems have limitations on the length and type of characters that can be used in file names.</p>
<pre class="r"><code>library(dplyr)
library(readr)
pizza_total &lt;- filter(pizza_total, pubyear &gt;= 1990, pubyear &lt;= 2012)
write_csv(pizza_total, &quot;pizza_total_1990_2012.csv&quot;)
pizza_total</code></pre>
<pre><code>## # A tibble: 23 x 2
##    pubyear publications
##      &lt;int&gt;        &lt;dbl&gt;
##  1    1990          139
##  2    1991          154
##  3    1992          212
##  4    1993          201
##  5    1994          162
##  6    1995          173
##  7    1996          180
##  8    1997          186
##  9    1998          212
## 10    1999          290
## # ... with 13 more rows</code></pre>
<p>When we print pizza_total to the console we will see that the data now covers the period 1990-2012. When using <code>filter()</code> on values in this way it is important to remember to apply this filter to any subsequent operations on the data (such as applicants) so that it matches the same data period.</p>
<p>To see our .csv file we can head over to the Files tab and, assuming that we have created a project, the file will now appear in the list of project files. Clicking on the file name will display the raw unformatted data in RStudio.</p>
</div>
</div>
<div id="simplify-code-with-pipes" class="section level2">
<h2>Simplify code with pipes <code>%&gt;%</code></h2>
<p>So far we have handled the code one line at a time. But, one of the great strengths of using a programming language is that we can run multiple lines of code together. There are two basic ways that we can do this.</p>
<p>We will create a new temporary object <code>df</code> to demonstrate this.</p>
<ol style="list-style-type: decimal">
<li>The standard way</li>
</ol>
<pre class="r"><code>library(dplyr)
library(ggplot2)
df &lt;- select(pizza, publication_number, publication_year)
df &lt;- mutate(df, n = sum(publication_number = 1))
df &lt;- count(df, publication_year, wt = n)
df &lt;- rename(df, pubyear = publication_year, publications = nn)
df &lt;- filter(df, pubyear &gt;= 1990, pubyear &lt;= 2012)
qplot(x = pubyear, y = publications, data = df, geom = &quot;line&quot;)</code></pre>
<p>The code we have just created is six lines long. If we select all of this code and run it in one go it will produce our graph.</p>
<p>One feature of this code is that each time we run a function on the object total we name it at the start of each function (e.g. mutate(df…)) and then we overwrite the object.</p>
<p>We can save quite a lot of typing and reduce the complexity of the code using the pipe operator introduced by the the <code>magrittr</code> package and then adopted in Hadley Wickham’s data wrangling and tidying packages.</p>
<ol start="2" style="list-style-type: decimal">
<li>Using pipes <code>%&gt;%</code></li>
</ol>
<p>Pipes are now a very popular way of writing R code because they simplify writing R code and speed it up. The most popular pipe is <code>%&gt;%</code> which means “this” then “that”. In this case we are going to create a new temporary object <code>df1</code> by first applying select to pizza, then mutate, count, rename and filter. Note that we only name our dataset once (in <code>select()</code>) and we do not need to keep overwriting the object.</p>
<pre class="r"><code>library(dplyr)
library(ggplot2)
df1 &lt;- select(pizza, publication_number, publication_year) %&gt;% mutate(n = sum(publication_number = 1)) %&gt;% 
    count(publication_year, wt = n) %&gt;% rename(pubyear = publication_year, publications = nn) %&gt;% 
    filter(pubyear &gt;= 1990, pubyear &lt;= 2012) %&gt;% qplot(x = pubyear, y = publications, 
    data = ., geom = &quot;line&quot;) %&gt;% print()</code></pre>
<p><img src="/post/2016-04-20-infographics_files/figure-html/piped-1.png" width="800px" style="display: block; margin: auto;" /></p>
<!---![](images_foot/infogram/fig2_infographic_qplot.png)--->
<p>In the standard code we typed <code>df</code> nine times to arrive at the same result. Using pipes we typed df1 once. Of greater importance is that the use of pipes simplifies the structure of R code by introducing a basic “this” then “that” logic which makes it easier to understand.</p>
<p>One point to note about this code is that <code>qplot()</code> requires us to name our data (in this case <code>df1</code>). However, <code>df1</code> is actually the final output of the code and does not exist as an input object before the final line is run. So, if we attempt to use <code>data = df1</code> in <code>qplot()</code> we will receive an error message. The way around this is to use <code>.</code> in place of our data object. That way <code>qplot()</code> will know we want to graph the outputs of the earlier code. Finally, we need to add an explicit call to <code>print()</code> to display the graph (without this the code will work but we will not see the graph).</p>
<p>If we now inspect the structure of the df1 object (using <code>str(df1)</code>) in the console, it will be a list. The reason for this is that it is an object with mixed components, including a data.frame with our data plus additional data setting out the contents of the plot. As there is no direct link between R and our infographics software this will create problems for us later because the infographics software won’t know how to interpret the list object. So, it is generally a good idea to use a straight data.frame by excluding the call to <code>qplot</code> and adding it later when needed as follows.</p>
<pre class="r"><code>library(dplyr)
library(ggplot2)
df2 &lt;- select(pizza, publication_number, publication_year) %&gt;% mutate(n = sum(publication_number = 1)) %&gt;% 
    count(publication_year, wt = n) %&gt;% rename(pubyear = publication_year, publications = nn) %&gt;% 
    filter(pubyear &gt;= 1990, pubyear &lt;= 2012) %&gt;% print()</code></pre>
<pre><code>## # A tibble: 23 x 2
##    pubyear publications
##      &lt;int&gt;        &lt;dbl&gt;
##  1    1990          139
##  2    1991          154
##  3    1992          212
##  4    1993          201
##  5    1994          162
##  6    1995          173
##  7    1996          180
##  8    1997          186
##  9    1998          212
## 10    1999          290
## # ... with 13 more rows</code></pre>
<p>Note that in this case the only change is that we need to explicitly include the reference to the df2 data frame as the data argument in the call to <code>qplot()</code>.</p>
<pre class="r"><code>library(ggplot2)
qplot(x = pubyear, y = publications, data = df2, geom = &quot;line&quot;)</code></pre>
<p><img src="/post/2016-04-20-infographics_files/figure-html/df2_qplot-1.png" width="800px" style="display: block; margin: auto;" /></p>
</div>
<div id="harmonising-data" class="section level2">
<h2>Harmonising data</h2>
<p>One challenge with creating multiple tables from a baseline dataset is keeping track of subdatasets. At the moment we have two basic objects we will be working with:</p>
<ol style="list-style-type: decimal">
<li><code>pizza</code> - our raw dataset</li>
<li><code>pizza_total</code> - created via <code>pizza_number</code> limited to 1990_2012.</li>
</ol>
<p>In the remainder of the chapter we will want to create some additional datasets from our pizza dataset. These are:</p>
<ol style="list-style-type: decimal">
<li>Country trends</li>
<li>Applicants</li>
<li>International Patent Classification (IPC) Class</li>
<li>Phrases</li>
<li>Google</li>
<li>Google IPC</li>
<li>Google phrases</li>
</ol>
<p>We need to make sure that any data that we generate from our raw dataset matches the period for the <code>pizza_total</code> dataset. If we do not do this there is a risk that we will generate subdatasets with counts for the raw pizza dataset.</p>
<p>To handle this we will use <code>filter()</code> to create a new baseline dataset with an unambiguous name.</p>
<pre class="r"><code>library(dplyr)
pizza_1990_2012 &lt;- rename(pizza, pubyear = publication_year) %&gt;% filter(pubyear &gt;= 
    1990, pubyear &lt;= 2012)
pizza_1990_2012</code></pre>
<pre><code>## # A tibble: 8,262 x 31
##                    applicants_cleaned applicants_cleaned_type
##                                 &lt;chr&gt;                   &lt;chr&gt;
##  1                               &lt;NA&gt;                  People
##  2            Lazarillo De Tormes S L               Corporate
##  3                               &lt;NA&gt;                  People
##  4                 Depoortere, Thomas                  People
##  5                   Frisco Findus Ag               Corporate
##  6         Bicycle Tools Incorporated               Corporate
##  7                 Castiglioni, Carlo                  People
##  8                               &lt;NA&gt;                  People
##  9              Bujalski, Wlodzimierz                  People
## 10 Ehrno Flexible A/S; Stergaard, Ole       Corporate; People
## # ... with 8,252 more rows, and 29 more variables:
## #   applicants_organisations &lt;chr&gt;, applicants_original &lt;chr&gt;,
## #   inventors_cleaned &lt;chr&gt;, inventors_original &lt;chr&gt;, ipc_class &lt;chr&gt;,
## #   ipc_codes &lt;chr&gt;, ipc_names &lt;chr&gt;, ipc_original &lt;chr&gt;,
## #   ipc_subclass_codes &lt;chr&gt;, ipc_subclass_detail &lt;chr&gt;,
## #   ipc_subclass_names &lt;chr&gt;, priority_country_code &lt;chr&gt;,
## #   priority_country_code_names &lt;chr&gt;, priority_data_original &lt;chr&gt;,
## #   priority_date &lt;chr&gt;, publication_country_code &lt;chr&gt;,
## #   publication_country_name &lt;chr&gt;, publication_date &lt;chr&gt;,
## #   publication_date_original &lt;chr&gt;, publication_day &lt;int&gt;,
## #   publication_month &lt;int&gt;, publication_number &lt;chr&gt;,
## #   publication_number_espacenet_links &lt;chr&gt;, pubyear &lt;int&gt;,
## #   title_cleaned &lt;chr&gt;, title_nlp_cleaned &lt;chr&gt;,
## #   title_nlp_multiword_phrases &lt;chr&gt;, title_nlp_raw &lt;chr&gt;,
## #   title_original &lt;chr&gt;</code></pre>
<p>In this case we start with a call to <code>rename()</code> to make this consistent with our pizza_total table and then use a pipe to filter the data on the year. Note here that when filtering raw data on a set of values it is important to inspect it first to check that the field is clean (e.g. not concatenated). If for some reason your data is concatenated (which happens quite a lot with patent data) then lookup <code>?tidyr::separate_rows</code>.</p>
<p>We are now in a position to create our country trends table.</p>
</div>
<div id="country-trends-using-spread" class="section level2">
<h2>Country Trends using <code>spread()</code></h2>
<p>There are two basic data formats: long and wide. Our pizza dataset is in long format because each column is a variable (e.g. <code>publication_country</code>) and each row in <code>publication_country</code> contains a country name. This is the most common and useful data format.</p>
<p>However, in some cases, such as <code>infogr.am</code> our visualisation software will expect the data to be in wide format. In this case each country name would become a variable (column name) with the years forming the rows and the number of records per year the observations. The key to this is the <code>tidyr()</code> function <code>spread()</code>.</p>
<p>As above we will start off by using <code>select()</code> to create a table with the fields that we want. We will then use <code>mutate()</code> to add a numeric field and then count up that data. To illustrate the process run this code (we will not create an object).</p>
<pre class="r"><code>library(dplyr)
select(pizza_1990_2012, publication_country_name, publication_number, pubyear) %&gt;% 
    mutate(n = sum(publication_number = 1)) %&gt;% count(publication_country_name, pubyear, 
    wt = n) %&gt;% print()</code></pre>
<pre><code>## # A tibble: 223 x 3
##    publication_country_name pubyear    nn
##                       &lt;chr&gt;   &lt;int&gt; &lt;dbl&gt;
##  1                   Canada    1990    19
##  2                   Canada    1991    49
##  3                   Canada    1992    66
##  4                   Canada    1993    59
##  5                   Canada    1994    50
##  6                   Canada    1995    39
##  7                   Canada    1996    36
##  8                   Canada    1997    45
##  9                   Canada    1998    46
## 10                   Canada    1999    47
## # ... with 213 more rows</code></pre>
<p>When we run this code we will see the results in long format. We now want to take our <code>publication_country_name</code> column and spread it to form columns with <code>nn</code> as the values.</p>
<p>In using spread note that it takes a data argument (<code>pizza_1990_2012</code>), a key (<code>publication_country_name</code>), and value column (<code>nn</code>) (created from <code>count()</code>). We are using pipes so the data only needs to be named in the first line. For additional arguments see <code>?spread()</code>.</p>
<pre class="r"><code>library(dplyr)
library(tidyr)
country_totals &lt;- select(pizza_1990_2012, publication_country_name, publication_number, 
    pubyear) %&gt;% mutate(n = sum(publication_number = 1)) %&gt;% count(publication_country_name, 
    pubyear, wt = n) %&gt;% spread(publication_country_name, nn)
country_totals</code></pre>
<pre><code>## # A tibble: 23 x 17
##    pubyear Canada China `Eurasian Patent Organization` `European Patent Office`
##  *   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt;                          &lt;dbl&gt;                    &lt;dbl&gt;
##  1    1990     19    NA                             NA                       22
##  2    1991     49    NA                             NA                       29
##  3    1992     66    NA                             NA                       36
##  4    1993     59    NA                             NA                       29
##  5    1994     50    NA                             NA                       26
##  6    1995     39    NA                             NA                       29
##  7    1996     36     1                             NA                       27
##  8    1997     45    NA                             NA                       34
##  9    1998     46    NA                             NA                       36
## 10    1999     47     2                              2                       60
## # ... with 13 more rows, and 12 more variables: Germany &lt;dbl&gt;, Israel &lt;dbl&gt;,
## #   Japan &lt;dbl&gt;, `Korea, Republic of` &lt;dbl&gt;, Mexico &lt;dbl&gt;, `Patent Co-operation
## #   Treaty` &lt;dbl&gt;, Portugal &lt;dbl&gt;, `Russian Federation` &lt;dbl&gt;, Singapore &lt;dbl&gt;,
## #   `South Africa` &lt;dbl&gt;, Spain &lt;dbl&gt;, `United States of America` &lt;dbl&gt;</code></pre>
<p>We now have data in wide format.</p>
<p>In some cases, such as infogr.am, visualisation software may expect the country names to be the name of rows and the column names to be years . We can modify our call to <code>spread()</code> by replacing the <code>publication_country_name</code> with <code>pubyear</code>. Then we will write the data to disk for use in our infographic.</p>
<pre class="r"><code>library(dplyr)
library(readr)
country_totals &lt;- select(pizza_1990_2012, publication_country_name, publication_number, pubyear) %&gt;%
  mutate(n = sum(publication_number = 1)) %&gt;% 
  count(publication_country_name, pubyear, wt = n) %&gt;% # note n
  spread(pubyear, nn) # note nn
country_totals</code></pre>
<pre><code>## # A tibble: 16 x 24
##        publication_country_name `1990` `1991` `1992` `1993` `1994` `1995`
##  *                        &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
##  1                       Canada     19     49     66     59     50     39
##  2                        China     NA     NA     NA     NA     NA     NA
##  3 Eurasian Patent Organization     NA     NA     NA     NA     NA     NA
##  4       European Patent Office     22     29     36     29     26     29
##  5                      Germany      2      2      2      2      5      2
##  6                       Israel     NA     NA      1     NA     NA      1
##  7                        Japan     NA     NA     NA     NA     NA     NA
##  8           Korea, Republic of     NA     NA     NA      1     NA     NA
##  9                       Mexico     NA     NA     NA     NA     NA     NA
## 10   Patent Co-operation Treaty      8     13     31     16     20     22
## 11                     Portugal     NA     NA     NA     NA     NA     NA
## 12           Russian Federation     NA     NA     NA     NA     NA     NA
## 13                    Singapore     NA     NA     NA     NA     NA     NA
## 14                 South Africa      2      3      3      3      3      1
## 15                        Spain     NA     NA     NA     NA     NA     NA
## 16     United States of America     86     58     73     91     58     79
## # ... with 17 more variables: `1996` &lt;dbl&gt;, `1997` &lt;dbl&gt;, `1998` &lt;dbl&gt;,
## #   `1999` &lt;dbl&gt;, `2000` &lt;dbl&gt;, `2001` &lt;dbl&gt;, `2002` &lt;dbl&gt;, `2003` &lt;dbl&gt;,
## #   `2004` &lt;dbl&gt;, `2005` &lt;dbl&gt;, `2006` &lt;dbl&gt;, `2007` &lt;dbl&gt;, `2008` &lt;dbl&gt;,
## #   `2009` &lt;dbl&gt;, `2010` &lt;dbl&gt;, `2011` &lt;dbl&gt;, `2012` &lt;dbl&gt;</code></pre>
<pre class="r"><code>write_csv(country_totals, &quot;pizza_country_1990_2012.csv&quot;)</code></pre>
<p>To restore the data to long format we would need to use <code>gather()</code> as the counterpart to <code>spread()</code>. <code>gather()</code> takes a dataset, a key for the name of the column we want to gather the countries into, a value for the numeric count (in this case n), and finally the positions of the columns to gather in. Note here that we need to look up the column positions in <code>country_totals</code> (e.g. using <code>View()</code>) or count the columns using <code>ncol(country_totals)</code>.</p>
<pre class="r"><code>library(dplyr)
gather(country_totals, year, n, 2:24) %&gt;% print()</code></pre>
<pre><code>## # A tibble: 368 x 3
##        publication_country_name  year     n
##                           &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;
##  1                       Canada  1990    19
##  2                        China  1990    NA
##  3 Eurasian Patent Organization  1990    NA
##  4       European Patent Office  1990    22
##  5                      Germany  1990     2
##  6                       Israel  1990    NA
##  7                        Japan  1990    NA
##  8           Korea, Republic of  1990    NA
##  9                       Mexico  1990    NA
## 10   Patent Co-operation Treaty  1990     8
## # ... with 358 more rows</code></pre>
<p>The combination of spread and gather work really well to prepare data in formats that are expected by other software. However, one of the main issues we encounter with patent data is that our data is not tidy because various fields are concatenated.</p>
</div>
<div id="tidying-data---separating-and-gathering" class="section level2">
<h2>Tidying data - Separating and Gathering</h2>
<p>In patent data we often see concatenated fields with a separator (normally a <code>;</code>). These are typically applicant names, inventor names, International Patent Classification (IPC) codes, or document numbers (priority numbers, family numbers). We need to <code>tidy</code> this data prior to data cleaning (such as cleaning names) or to prepare for analysis and visualisation. For more on the concept of tidy data read <a href="http://vita.had.co.nz/papers/tidy-data.pdf">Hadley Wickham’s Tidy Data article</a>. The new <a href="http://r4ds.had.co.nz/tidy-data.html">R for Data Science book</a> by Garrett Grolemund and Hadley Wickham (see Chapter 12) is also strongly recommended.</p>
<p>To tidy patent data we will typically need to do two things.</p>
<ol style="list-style-type: decimal">
<li><p>Separate the data so that each cell contains a unique data point (e.g. a name, code or publication number). This normally involves separating data into columns.</p></li>
<li><p>Gathering the data back in. This involves transforming the data in the columns we have created into rows.</p></li>
</ol>
<p>Separating data into columns is very easy in tools such as Excel. However, gathering the data back into separate rows is remarkably difficult. Happily, this is very easy to do in R with the <code>tidyr</code> package.</p>
<p>The <code>tidyr</code> package contains three functions that are very useful when working with patent data. When dealing with concatenated fields in columns the key function is <code>separate_rows</code>.</p>
<p>Here we will work with the <code>applicants_cleaned</code> field in the pizza dataset. This field contains concatenated names with a <code>;</code> as the separator. For example, on lines 1_9 there are single applicant names or NA values. However, on lines 10 and line 59 we see:</p>
<pre class="r"><code>Ehrno Flexible A/S; Stergaard, Ole
Farrell Brian; Mcnulty John; Vishoot Lisa</code></pre>
<p>The problem here is that when we are dealing with thousands of lines of applicant names we don’t know how many names might be concatenated into each cell as a basis for separating the data into columns. Once we had split the columns (for example using Text to Columns in Excel) we would then need to work out how to gather the columns into rows. The <code>separate_rows()</code> function from <code>tidyr</code> makes light work of this problem. To use the function we name the dataset, the column we want to separate into rows and the separator (sep).</p>
<pre class="r"><code>library(dplyr)
library(tidyr)
pizza1 &lt;- separate_rows(pizza_1990_2012, applicants_cleaned, sep = &quot;;&quot;)
pizza1</code></pre>
<pre><code>## # A tibble: 12,729 x 31
##    applicants_cleaned_type   applicants_organisations
##                      &lt;chr&gt;                      &lt;chr&gt;
##  1                  People                       &lt;NA&gt;
##  2               Corporate    Lazarillo De Tormes S L
##  3                  People                       &lt;NA&gt;
##  4                  People                       &lt;NA&gt;
##  5               Corporate           Frisco Findus Ag
##  6               Corporate Bicycle Tools Incorporated
##  7                  People                       &lt;NA&gt;
##  8                  People                       &lt;NA&gt;
##  9                  People                       &lt;NA&gt;
## 10       Corporate; People         Ehrno Flexible A/S
## # ... with 12,719 more rows, and 29 more variables: applicants_original &lt;chr&gt;,
## #   inventors_cleaned &lt;chr&gt;, inventors_original &lt;chr&gt;, ipc_class &lt;chr&gt;,
## #   ipc_codes &lt;chr&gt;, ipc_names &lt;chr&gt;, ipc_original &lt;chr&gt;,
## #   ipc_subclass_codes &lt;chr&gt;, ipc_subclass_detail &lt;chr&gt;,
## #   ipc_subclass_names &lt;chr&gt;, priority_country_code &lt;chr&gt;,
## #   priority_country_code_names &lt;chr&gt;, priority_data_original &lt;chr&gt;,
## #   priority_date &lt;chr&gt;, publication_country_code &lt;chr&gt;,
## #   publication_country_name &lt;chr&gt;, publication_date &lt;chr&gt;,
## #   publication_date_original &lt;chr&gt;, publication_day &lt;int&gt;,
## #   publication_month &lt;int&gt;, publication_number &lt;chr&gt;,
## #   publication_number_espacenet_links &lt;chr&gt;, pubyear &lt;int&gt;,
## #   title_cleaned &lt;chr&gt;, title_nlp_cleaned &lt;chr&gt;,
## #   title_nlp_multiword_phrases &lt;chr&gt;, title_nlp_raw &lt;chr&gt;,
## #   title_original &lt;chr&gt;, applicants_cleaned &lt;chr&gt;</code></pre>
<p>Our original dataset contained 8,262 rows. Our new dataset split on applicant names contains 12,729 rows. The function has moved our target column from column 1 to column 31 in the data frame. We can easily move it back to inspect.</p>
<pre class="r"><code>library(dplyr)
pizza1 &lt;- select(pizza1, 31, 1:30)</code></pre>
<p><code>separate_rows()</code> has done a great job but one of the problems with concatenated names is extra white space around the separator. We will deal with this next.</p>
<div id="trimming-with-stringr" class="section level3">
<h3>Trimming with <code>stringr</code></h3>
<p>If we inspect the bottom of the column by subsetting into it using <code>$</code> we will see that a lot of the names have a leading whitespace space. This results from the separate exercise where the <code>;</code> is actually <code>;space</code>. Take a look at the last few rows of the data using <code>tail()</code>.</p>
<pre class="r"><code>tail(pizza1$applicants_cleaned, 20)</code></pre>
<pre><code>##  [1] &quot;Yahoo! Inc&quot;                        &quot;Clarcor Inc&quot;                      
##  [3] &quot;Holden Jeffrey A&quot;                  &quot; Vengroff Darren E&quot;               
##  [5] &quot;Casper Jeffrey L&quot;                  &quot; Erickson Braden J&quot;               
##  [7] &quot; Oppenheimer Alan A&quot;               &quot; Ray Madonna M&quot;                   
##  [9] &quot; Weber Jean L&quot;                     &quot;Pandey Neena&quot;                     
## [11] &quot; Sharma Sudhanshu&quot;                 &quot; Verizon Patent And Licensing Inc&quot;
## [13] &quot;Pandey Neena&quot;                      &quot; Sharma Sudhanshu&quot;                
## [15] &quot;Brown Michael&quot;                     &quot; Urban Scott&quot;                     
## [17] &quot;Brown Michael&quot;                     &quot; Urban Scott&quot;                     
## [19] &quot;Cole Lorin R&quot;                      &quot; Middleton Scott W&quot;</code></pre>
<p>This is a big issue because any counts that we make later on using the applicants_cleaned field will treat “Oppenheimer Alan A” and &quot; Oppenheimer Alan A&quot; as separate names when they should be grouped together.</p>
<p>We can address this in a couple of ways. One approach is to recognise that actually our separator is not a simple <code>&quot;;&quot;</code> but <code>&quot;;space&quot;</code> in our call to <code>separate_rows()</code>. In that case the call to <code>separate_rows()</code> would actually be <code>sep = &quot;; &quot;</code>. We will add a line of code to illustrate the impact of this change.</p>
<pre class="r"><code>tmp &lt;- separate_rows(pizza_1990_2012, applicants_cleaned, sep = &quot;; &quot;)
tail(tmp$applicants_cleaned, 20)</code></pre>
<pre><code>##  [1] &quot;Yahoo! Inc&quot;                       &quot;Clarcor Inc&quot;                     
##  [3] &quot;Holden Jeffrey A&quot;                 &quot;Vengroff Darren E&quot;               
##  [5] &quot;Casper Jeffrey L&quot;                 &quot;Erickson Braden J&quot;               
##  [7] &quot;Oppenheimer Alan A&quot;               &quot;Ray Madonna M&quot;                   
##  [9] &quot;Weber Jean L&quot;                     &quot;Pandey Neena&quot;                    
## [11] &quot;Sharma Sudhanshu&quot;                 &quot;Verizon Patent And Licensing Inc&quot;
## [13] &quot;Pandey Neena&quot;                     &quot;Sharma Sudhanshu&quot;                
## [15] &quot;Brown Michael&quot;                    &quot;Urban Scott&quot;                     
## [17] &quot;Brown Michael&quot;                    &quot;Urban Scott&quot;                     
## [19] &quot;Cole Lorin R&quot;                     &quot;Middleton Scott W&quot;</code></pre>
<p>Another way to address this, is to use the <code>str_trim()</code> function from the <code>stringr</code> package.</p>
<p>We can address this problem using a function from the <code>stringr</code> package <code>str_trim()</code>. We have a choice with <code>str_trim()</code> on whether to trim the whitespace on the right, left or both. Here we will choose both.</p>
<p>Because we are seeking to modify an existing column (not to create a new vector or data.frame) we will use <code>$</code> to select the column and as the data for the <code>str_trim()</code> function. That will apply the function to the applicants column in pizza1.</p>
<pre class="r"><code>library(stringr)
pizza1$applicants_cleaned &lt;- str_trim(pizza1$applicants_cleaned, side = &quot;both&quot;)
tail(pizza1$applicants_cleaned, 20)</code></pre>
<pre><code>##  [1] &quot;Yahoo! Inc&quot;                       &quot;Clarcor Inc&quot;                     
##  [3] &quot;Holden Jeffrey A&quot;                 &quot;Vengroff Darren E&quot;               
##  [5] &quot;Casper Jeffrey L&quot;                 &quot;Erickson Braden J&quot;               
##  [7] &quot;Oppenheimer Alan A&quot;               &quot;Ray Madonna M&quot;                   
##  [9] &quot;Weber Jean L&quot;                     &quot;Pandey Neena&quot;                    
## [11] &quot;Sharma Sudhanshu&quot;                 &quot;Verizon Patent And Licensing Inc&quot;
## [13] &quot;Pandey Neena&quot;                     &quot;Sharma Sudhanshu&quot;                
## [15] &quot;Brown Michael&quot;                    &quot;Urban Scott&quot;                     
## [17] &quot;Brown Michael&quot;                    &quot;Urban Scott&quot;                     
## [19] &quot;Cole Lorin R&quot;                     &quot;Middleton Scott W&quot;</code></pre>
<p>Note that when using <code>str_trim()</code> we use subsetting to modify the applicants column in place. There is possibly a more efficient way of doing this with pipes but this appears difficult because the data.frame needs to exist for <code>str_trim()</code> to act on in place or we end up with a vector of applicant names rather than a data.frame. A solution to this problem is provided on Stack Overflow<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>.</p>
<p>In practice, the most efficient solution in this case is to recognise that the separator for <code>separate_rows</code> is <code>&quot;;space&quot;</code>. However, that will not always be true making the tools in <code>stringr</code> invaluable. To learn more about string manipulation in R try <a href="http://r4ds.had.co.nz/strings.html">Chapter 14 of R for Data Science by Garrett Grolemund and Hadley Wickham</a>.</p>
<p>We can tie the steps so far together using pipes into the following simpler code that we will become the applicants table for use in the infographic. We will add a call to rename and rename applicants_cleaned to tidy up.</p>
<pre class="r"><code>library(dplyr)
library(tidyr)
library(stringr)
applicants &lt;- rename(pizza, pubyear = publication_year) %&gt;% filter(pubyear &gt;= 1990, 
    pubyear &lt;= 2012) %&gt;% separate_rows(applicants_cleaned, sep = &quot;; &quot;) %&gt;% rename(applicants = applicants_cleaned) %&gt;% 
    select(31, 1:30)  # moves separated column to the beginning
applicants</code></pre>
<pre><code>## # A tibble: 12,729 x 31
##                    applicants applicants_cleaned_type
##                         &lt;chr&gt;                   &lt;chr&gt;
##  1                       &lt;NA&gt;                  People
##  2    Lazarillo De Tormes S L               Corporate
##  3                       &lt;NA&gt;                  People
##  4         Depoortere, Thomas                  People
##  5           Frisco Findus Ag               Corporate
##  6 Bicycle Tools Incorporated               Corporate
##  7         Castiglioni, Carlo                  People
##  8                       &lt;NA&gt;                  People
##  9      Bujalski, Wlodzimierz                  People
## 10         Ehrno Flexible A/S       Corporate; People
## # ... with 12,719 more rows, and 29 more variables:
## #   applicants_organisations &lt;chr&gt;, applicants_original &lt;chr&gt;,
## #   inventors_cleaned &lt;chr&gt;, inventors_original &lt;chr&gt;, ipc_class &lt;chr&gt;,
## #   ipc_codes &lt;chr&gt;, ipc_names &lt;chr&gt;, ipc_original &lt;chr&gt;,
## #   ipc_subclass_codes &lt;chr&gt;, ipc_subclass_detail &lt;chr&gt;,
## #   ipc_subclass_names &lt;chr&gt;, priority_country_code &lt;chr&gt;,
## #   priority_country_code_names &lt;chr&gt;, priority_data_original &lt;chr&gt;,
## #   priority_date &lt;chr&gt;, publication_country_code &lt;chr&gt;,
## #   publication_country_name &lt;chr&gt;, publication_date &lt;chr&gt;,
## #   publication_date_original &lt;chr&gt;, publication_day &lt;int&gt;,
## #   publication_month &lt;int&gt;, publication_number &lt;chr&gt;,
## #   publication_number_espacenet_links &lt;chr&gt;, pubyear &lt;int&gt;,
## #   title_cleaned &lt;chr&gt;, title_nlp_cleaned &lt;chr&gt;,
## #   title_nlp_multiword_phrases &lt;chr&gt;, title_nlp_raw &lt;chr&gt;,
## #   title_original &lt;chr&gt;</code></pre>
<p>We will want to create a plot with the applicants data in our infographic software. For that we need to introduce a field to count on. We might also want to establish a cut off point based on the number of records per applicant.</p>
<p>In this code we will simply print the applicants ranked in descending order. The second to last line of the code provides a filter on the number of records. This value can be changed after inspecting the data. The final line omits NA values (otherwise the top result) where an applicant name is not available.</p>
<pre class="r"><code>library(tidyr)
library(dplyr)
applicant_count &lt;- select(applicants, applicants, publication_number) %&gt;% mutate(n = sum(publication_number = 1)) %&gt;% 
    count(applicants, wt = n) %&gt;% arrange(desc(nn)) %&gt;% filter(nn &gt;= 1) %&gt;% na.omit()
applicant_count</code></pre>
<pre><code>## # A tibble: 6,178 x 2
##                              applicants    nn
##                                   &lt;chr&gt; &lt;dbl&gt;
##  1 Graphic Packaging International, Inc   154
##  2            Kraft Foods Holdings, Inc   132
##  3                           Google Inc   123
##  4                Microsoft Corporation    88
##  5                The Pillsbury Company    83
##  6                   General Mills, Inc    77
##  7                               Nestec    77
##  8         The Procter &amp; Gamble Company    59
##  9                       Pizza Hut, Inc    57
## 10                           Yahoo! Inc    54
## # ... with 6,168 more rows</code></pre>
<p>If we inspect applicant count using <code>View(applicant_count)</code> we have 6,178 rows. That is far too many to display in an infographic. So, next we will filter the data on the value for the top ten (54). Then we will write the data to a .csv file using the simple <code>write_csv()</code> from <code>readr</code>.</p>
<pre class="r"><code>library(dplyr)
library(tidyr)
library(readr)
applicant_count &lt;- select(applicants, applicants, publication_number) %&gt;% mutate(n = sum(publication_number = 1)) %&gt;% 
    count(applicants, wt = n) %&gt;% arrange(desc(nn)) %&gt;% filter(nn &gt;= 54) %&gt;% na.omit()
applicant_count</code></pre>
<pre><code>## # A tibble: 10 x 2
##                              applicants    nn
##                                   &lt;chr&gt; &lt;dbl&gt;
##  1 Graphic Packaging International, Inc   154
##  2            Kraft Foods Holdings, Inc   132
##  3                           Google Inc   123
##  4                Microsoft Corporation    88
##  5                The Pillsbury Company    83
##  6                   General Mills, Inc    77
##  7                               Nestec    77
##  8         The Procter &amp; Gamble Company    59
##  9                       Pizza Hut, Inc    57
## 10                           Yahoo! Inc    54</code></pre>
<pre class="r"><code>write_csv(applicant_count, &quot;pizza_applicants_1990_2012.csv&quot;)</code></pre>
<p>When we inspect <code>applicant_count</code> we will see that Graphic Packaging International is the top result with 154 results with Google ranking third with 123 results followed by Microsoft. This could suggest that Google and Microsoft are suddenly entering the market for online pizza sales or pizza making software or, as is more likely, that there are uses other uses of the word pizza in patent data that we are not aware of.</p>
<p>As part of our infographic we will want to explore this intriguing result in more detail. We can do this by creating a subdataset for Google using <code>filter()</code>.</p>
</div>
</div>
<div id="selecting-applicants-using-filter" class="section level2">
<h2>Selecting applicants using <code>filter()</code></h2>
<p>As we saw above, while <code>select()</code> functions with columns, <code>filter()</code> from <code>dplyr</code> works with rows. Here we will filter the data to select the rows in the applicants column that contain Google Inc. and then write that to a .csv for use in our infographic. Note the use of double <code>==</code> and the quotes around “Google Inc”.</p>
<pre class="r"><code>library(dplyr)
library(readr)
google &lt;- filter(applicants, applicants == &quot;Google Inc&quot;)
google</code></pre>
<pre><code>## # A tibble: 123 x 31
##    applicants applicants_cleaned_type applicants_organisations
##         &lt;chr&gt;                   &lt;chr&gt;                    &lt;chr&gt;
##  1 Google Inc       Corporate; People               Google Inc
##  2 Google Inc               Corporate               Google Inc
##  3 Google Inc       Corporate; People               Google Inc
##  4 Google Inc       Corporate; People               Google Inc
##  5 Google Inc               Corporate               Google Inc
##  6 Google Inc               Corporate               Google Inc
##  7 Google Inc               Corporate               Google Inc
##  8 Google Inc       Corporate; People               Google Inc
##  9 Google Inc               Corporate               Google Inc
## 10 Google Inc               Corporate               Google Inc
## # ... with 113 more rows, and 28 more variables: applicants_original &lt;chr&gt;,
## #   inventors_cleaned &lt;chr&gt;, inventors_original &lt;chr&gt;, ipc_class &lt;chr&gt;,
## #   ipc_codes &lt;chr&gt;, ipc_names &lt;chr&gt;, ipc_original &lt;chr&gt;,
## #   ipc_subclass_codes &lt;chr&gt;, ipc_subclass_detail &lt;chr&gt;,
## #   ipc_subclass_names &lt;chr&gt;, priority_country_code &lt;chr&gt;,
## #   priority_country_code_names &lt;chr&gt;, priority_data_original &lt;chr&gt;,
## #   priority_date &lt;chr&gt;, publication_country_code &lt;chr&gt;,
## #   publication_country_name &lt;chr&gt;, publication_date &lt;chr&gt;,
## #   publication_date_original &lt;chr&gt;, publication_day &lt;int&gt;,
## #   publication_month &lt;int&gt;, publication_number &lt;chr&gt;,
## #   publication_number_espacenet_links &lt;chr&gt;, pubyear &lt;int&gt;,
## #   title_cleaned &lt;chr&gt;, title_nlp_cleaned &lt;chr&gt;,
## #   title_nlp_multiword_phrases &lt;chr&gt;, title_nlp_raw &lt;chr&gt;,
## #   title_original &lt;chr&gt;</code></pre>
<pre class="r"><code>write_csv(google, &quot;google_1990_2012.csv&quot;)</code></pre>
<p>Note that the correct result for the period 1990 to 2012 for Google is 123 records from 191 records across the whole pizza dataset. The correct result will be achieved only where you use the filtered, separated and trimmed data we created in the applicants data frame.</p>
</div>
<div id="generating-ipc-tables" class="section level2">
<h2>Generating IPC Tables</h2>
<p>In the next step we will want to generate two tables containing International Patent Classification (IPC) data. IPC codes and the Cooperative Patent Classification (CPC, not present in this dataset) provide information on the technologies involved in a patent document. The IPC is hierarchical and proceeds from the general class level to the detailed group and subgroup level. Experience reveals that the majority of patent documents receive more than one IPC code to more fully describe the technological aspects of patent documents.</p>
<p>The pizza dataset contains IPC codes on the class and the subclass level in concatenated fields. One important consideration in using IPC data is that the descriptions are long and can be difficult for non-specialists to grasp. This can make visualising the data difficult and often requires manual efforts to edit labels for display.</p>
<p>We now want to generate three IPC tables.</p>
<ol style="list-style-type: decimal">
<li>A general IPC table for the pizza dataset</li>
<li>A general IPC table for the Google dataset</li>
<li>A more detailed IPC subclass table for the Google dataset</li>
</ol>
<p>For ease of presentation in an infographic we will use the <code>ipc_class</code> field. For many patent analytics purposes this will be too general. However it has the advantage of being easy to visualise.</p>
<p>To generate the table we can use a generic function based on the code developed for dealing with the applicants data. We will call the function patent_count().</p>
<pre class="r"><code>patent_count &lt;- function(data, col = &quot;&quot;, count_col = &quot;&quot;, n_results = n_results, sep = &quot;[^[:alnum:]]+&quot;) {
    p_count &lt;- dplyr::select_(data, col, count_col) %&gt;% tidyr::separate_rows_(col, 
        sep = sep) %&gt;% dplyr::mutate_(n = sum(count_col = 1)) %&gt;% dplyr::select(2:3)
    p_count %&gt;% dplyr::group_by_(col) %&gt;% dplyr::tally() %&gt;% dplyr::arrange(desc(nn)) %&gt;% 
        dplyr::rename(records = nn) %&gt;% dplyr::ungroup() %&gt;% na.omit() %&gt;% .[1:n_results, 
        ]
}</code></pre>
<p>The <code>patent_count()</code> function is based on the the code we developed for applicants. It contains variations to make it work as a function. The function takes four arguments:</p>
<ol style="list-style-type: decimal">
<li>col = the concatenated column that we want to split and gather back in</li>
<li>col_count = a column for generating counts (in this dataset the publication_number)</li>
<li>n_results = the number of results we want to see in the new table (typically 10 or 20 for visualisation). This is equivalent to the number of rows that you want to see.</li>
<li>sep = the separator to use to separate the data in col. With patent data this is almost always “;” (as <code>;space</code>.</li>
</ol>
<p>To generate the <code>ipc_class</code> data we can do the following and then write the file to .csv. Note that we have set the number of results <code>n_results</code> to 10.</p>
<pre class="r"><code>pizza_ipc_class &lt;- patent_count(data = pizza_1990_2012, col = &quot;ipc_class&quot;, count_col = &quot;publication_number&quot;, 
    n_results = 10, sep = &quot;;&quot;)
pizza_ipc_class</code></pre>
<pre><code>## # A tibble: 10 x 2
##                                               ipc_class records
##                                                   &lt;chr&gt;   &lt;dbl&gt;
##  1                                          A21: Baking    2218
##  2                                       G06: Computing    1209
##  3                             A23: Foods Or Foodstuffs    1058
##  4                                       B65: Conveying     903
##  5                             A23: Foods Or Foodstuffs     785
##  6                                       A47: Furniture     645
##  7                                       B65: Conveying     480
##  8  H05: Electric Techniques Not Otherwise Provided For     456
##  9                H04: Electric Communication Technique     427
## 10                H04: Electric Communication Technique     320</code></pre>
<pre class="r"><code>write_csv(pizza_ipc_class, &quot;pizza_ipcclass_1990_2012.csv&quot;)</code></pre>
<p>Note that this dataset is based on the main <code>pizza_1990_2012</code> dataset (including cases where no applicant name is available). The reason we have not used the applicants dataset is because that dataset will duplicate the IPC field for each split of an applicant name. As a result it will over count the IPCs by the number of applicants on a document name. As this suggests, it is important to be careful when working with data that has been tidied because of the impact on other counts.</p>
<p>This problem does not apply in the case of our Google data because the only applicant listed in that data is Google (excluding co-applicants). We can therefore safely use the Google dataset to identify the IPC codes.</p>
<pre class="r"><code>google_ipc_class &lt;- patent_count(data = google, col = &quot;ipc_class&quot;, count_col = &quot;publication_number&quot;, 
    n_results = 10, sep = &quot;;&quot;)
google_ipc_class</code></pre>
<pre><code>## # A tibble: 10 x 2
##                                 ipc_class records
##                                     &lt;chr&gt;   &lt;dbl&gt;
##  1                         G06: Computing      95
##  2                         G01: Measuring      14
##  3                         G09: Educating      11
##  4                         G06: Computing      10
##  5  H04: Electric Communication Technique      10
##  6  H04: Electric Communication Technique       7
##  7               G10: Musical Instruments       6
##  8                        G08: Signalling       1
##  9               G10: Musical Instruments       1
## 10                            A63: Sports       1</code></pre>
<pre class="r"><code>write_csv(google_ipc_class, &quot;google_ipcclass_1990_2012.csv&quot;)</code></pre>
<p>There are only 7 classes and as we might expect they are dominated by computing. We might want to dig into this in a little more detail and so let’s also create an IPC subclass field.</p>
<pre class="r"><code>google_ipc_subclass &lt;- patent_count(data = google, col = &quot;ipc_subclass_detail&quot;, count_col = &quot;publication_number&quot;, 
    n_results = 10, sep = &quot;;&quot;)
google_ipc_subclass</code></pre>
<pre><code>## # A tibble: 10 x 2
##                                                                 ipc_subclass_detail
##                                                                               &lt;chr&gt;
##  1                                           G06F: Electric Digital Data Processing
##  2                                    G01C: Measuring Distances, Levels Or Bearings
##  3  G06Q: Data Processing Systems Or Methods, Specially Adapted For Administrative,
##  4 G06Q: Data Processing Systems Or Methods, Specially Adapted For Administrative, 
##  5                                    G09B: Educational Or Demonstration Appliances
##  6                                           G06F: Electric Digital Data Processing
##  7                                            H04W: Wireless Communication Networks
##  8                                               G10L: Speech Analysis Or Synthesis
##  9  G09G: Arrangements Or Circuits For Control Of Indicating Devices Using Static M
## 10                                                               H04B: Transmission
## # ... with 1 more variables: records &lt;dbl&gt;</code></pre>
<pre class="r"><code>write_csv(google_ipc_subclass, &quot;google_ipcsubclass_1990_2012.csv&quot;)</code></pre>
<p>We now have the data on technology areas that we need to understand our data. The next and final step is to generate data from the text fields.</p>
<div id="phrases-tables" class="section level3">
<h3>Phrases Tables</h3>
<p>We will be using data from words and phrases in the titles of patent documents for use in a word cloud in our infographic. It is possible to generate this type of data in R directly using the <code>tm</code> and <code>NLP</code> packages. Our pizza dataset already contains a title field broken down into phrases using Vantagepoint software and so we will use that. We will use the field <code>title_nlp_multiword_phrases</code> as phrases are generally more informative than individual words. Once again we will use our general <code>patent_count()</code> function although experimentation may be needed to identify the number of phrases that visualise well in a word cloud.</p>
<pre class="r"><code>pizza_phrases &lt;- patent_count(data = pizza_1990_2012, col = &quot;title_nlp_multiword_phrases&quot;, 
    count_col = &quot;publication_number&quot;, n_results = 15, sep = &quot;;&quot;)
pizza_phrases</code></pre>
<pre><code>## # A tibble: 15 x 2
##    title_nlp_multiword_phrases records
##                          &lt;chr&gt;   &lt;dbl&gt;
##  1                Food Product     135
##  2             Microwave Ovens      99
##  3                Food Product      44
##  4                 Crust Pizza      41
##  5               conveyor Oven      40
##  6             Microwave Ovens      38
##  7              Bakery Product      34
##  8                 Making Same      33
##  9               Baked Product      33
## 10                   Cook Food      32
## 11                  Pizza Oven      30
## 12                   pizza Box      30
## 13              Related Method      29
## 14           Microwave Cooking      28
## 15           microwave Heating      27</code></pre>
<pre class="r"><code>write_csv(pizza_phrases, &quot;pizza_phrases_1990_2012.csv&quot;)</code></pre>
<p>Now we do the same with the Google data.</p>
<pre class="r"><code>google_phrases &lt;- patent_count(data = google, col = &quot;title_nlp_multiword_phrases&quot;, 
    count_col = &quot;publication_number&quot;, n_results = 15, sep = &quot;;&quot;)
google_phrases</code></pre>
<pre><code>## # A tibble: 15 x 2
##             title_nlp_multiword_phrases records
##                                   &lt;chr&gt;   &lt;dbl&gt;
##  1                   Digital Map System      10
##  2 conversion Path Performance Measures       9
##  3                       Search Results       7
##  4                        Mobile Device       6
##  5                  Location Prominence       4
##  6                   Processing Queries       4
##  7               Geographical Relevance       4
##  8                 Local Search Results       4
##  9           Network Speech Recognizers       4
## 10                         Search Query       4
## 11                   indexing Documents       3
## 12        providing Profile Information       3
## 13          search Query Categorization       3
## 14                       Search Ranking       3
## 15 aspect-Based Sentiment Summarization       3</code></pre>
<pre class="r"><code>write_csv(google_phrases, &quot;google_phrases_1990_2012.csv&quot;)</code></pre>
<p>We now have the following .csv files.</p>
<ol style="list-style-type: decimal">
<li><code>pizza_total_1990_2012</code></li>
<li><code>pizza_country_1990_2012</code></li>
<li><code>pizza_applicants_1990_2012</code></li>
<li><code>pizza_ipcclass_1990_2012</code></li>
<li><code>pizza_phrases_1990_2012</code></li>
<li><code>Google_1990_2012</code></li>
<li><code>Google_ipclass_1990_2012</code></li>
<li><code>Google_ipcsubclass_1990_2012</code></li>
<li><code>Google_phrases-1990_2012</code></li>
</ol>
</div>
</div>
<div id="creating-an-infographic-in-infogr.am" class="section level2">
<h2>Creating an infographic in infogr.am</h2>
<p>If you are starting this chapter here then download the datasets we will be using as a single zip file from the Manual repository <a href="https://github.com/wipo-analytics/opensource-patent-analytics/blob/master/2_datasets/infographic/infographic.zip?raw=true">here</a> and then unzip the file.</p>
<p>We first need to sign up for a free account with <a href="https://infogr.am/">infogr.am</a></p>
<p><img src="/images/infogram/fig1_infogram_front.png" width="800px" style="display: block; margin: auto;" /></p>
<p>We will then see a page with some sample infographics to provide ideas to get you started.</p>
<p><img src="/images/infogram/fig2_infogram_login.png" width="800px" style="display: block; margin: auto;" /> Click on one of the infograms with a graph such as Trends in Something and then click inside the graph box itself and select the edit button in the top right.</p>
<p><img src="/images/infogram/fig3_infogram_findedit.png" width="800px" style="display: block; margin: auto;" /></p>
<p>This will open up a data panel with the toy data displayed.</p>
<p><img src="images/infogram/fig4_infogram_datapanel.png" width="800px" style="display: block; margin: auto;" /></p>
<p>We want to replace this data by choosing the upload button and selecting our <code>pizza_country_1990_2012.csv</code> file.</p>
<p><img src="/images/infogram/fig5_infogram_panelgraph.png" width="800px" style="display: block; margin: auto;" /></p>
<p>We now have a decent looking graph for our country trends data where we can see the number of records per country and year by hovering over the relevant data points. While some of the countries with low frequency data are crunched at the bottom (and would be better displayed in a separate graph), hovering over the data or over a country name will display the relevant country activity. We will therefore live with this.</p>
<p>We now want to start adding story elements by clicking on the edit button in the title. Next we can start adding new boxes using the menu icons on the right. Here we have changed the title, added a simple body text for the data credit and then a quote from someone describing themselves as the Head of Pizza Analytics.</p>
<p><img src="/images/infogram/fig6_infogram_paneltext.png" width="800px" style="display: block; margin: auto;" /></p>
<p>Next we need to start digging into the data using our IPC, applicants and phrases data.</p>
<p>To work with our IPC class data we will add a bar chart and load the data. To do this select the graph icon in the right and then Bar. Once again we will choose edit and then load our <code>pizza_ipcclass_1990_2012</code> dataset. Then we can add a descriptive text box. We can then continue to add elements as follows:</p>
<ol style="list-style-type: decimal">
<li>applicants bar chart</li>
<li>pizza phrases by selecting graph and word cloud</li>
<li>Google ipc-subclass</li>
<li>Google word cloud.</li>
</ol>
<p>One useful approach to developing an infographic is to start by adding the images and then add titles and text boxes to raise key points. In infogram new text boxes appear below existing boxes but can be repositioned by dragging and dropping boxes onto each other.</p>
<p>One nice feature of infogram is that it is easy to share the infographic with others through a url, an embed code or on facebook or via twitter.</p>
<p>At the end of the infographic it is a good idea to provide a link where the reader can obtain more information, such as the full report or the underlying data. In this case we will add a link to the Tableau workbook on pizza patent activity that we developed in an earlier <a href="https://public.tableau.com/profile/wipo.open.source.patent.analytics.manual#!/vizhome/pizzapatents/Overview">chapter</a>.</p>
<p>Our final infographic should look something like <a href="https://infogr.am/trends_in_something">this</a>.</p>
<div id="round-up" class="section level3">
<h3>Round Up</h3>
<p>In this chapter we have concentrated on using R to tidy patent data in order to create an online infographic using free software. Using our trusty pizza patent data from WIPO Patentscope we walked through the process of wrangling and tidying patent data first using short lines of code that we then combined into a reusable function. As this introduction to tidying data in R has hopefully revealed, R and packages such as <code>dplyr</code>, <code>tidyr</code> and <code>stringr</code> provide very useful tools for working with patent data, and they are free and well supported.</p>
<p>In the final part of the chapter we used the data we had generated in RStudio to create an infographic using infogr.am that we then shared online. Infogram is just one of a number of online infographic services and it is well worth trying other services such as <a href="https://www.easel.ly">easel.ly</a> to find a service that meets your needs.</p>
<p>As regular users of R will already know, it is already possible to produce all of these graphics (such as word clouds) directly in R using tools such as <code>ggplot2</code>, <code>plotly</code> and word clouds using packages such as <code>wordcloud</code>. Some of these topics have been covered in other chapters and for more on text mining and word clouds in R see this recent article on <a href="http://www.r-bloggers.com/building-wordclouds-in-r/">R-bloggers</a>. None of the infographic services we viewed appeared to offer an API that would enable a direct connection with R. There also seems to be a gap in R’s packages where infographics might sit with this <a href="http://www.r-bloggers.com/r-how-to-layout-and-design-an-infographic/">2015 R-bloggers article</a> providing a walk through on how to create a basic infographic.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p><a href="http://stackoverflow.com/questions/25975827/how-to-feed-the-result-of-a-pipe-chain-magrittr-to-an-object" class="uri">http://stackoverflow.com/questions/25975827/how-to-feed-the-result-of-a-pipe-chain-magrittr-to-an-object</a><a href="#fnref1">↩</a></p></li>
</ol>
</div>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdn.bootcss.com/highlight.js/9.11.0/highlight.min.js"></script>



<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/r.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="/js/math-code.js"></script>
<script async src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-113668064-1', 'auto');
ga('send', 'pageview');
</script>

  </body>
</html>

